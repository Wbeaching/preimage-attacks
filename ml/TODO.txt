1. Loss using all predicted solutions and ALL ground truth solutions
2. "Inference-mode" solver which uses model to search for optimal solutoin
3. Stochastic weight averaging?
4. Batch norm / other architectures / transformer



a. Each CNF can have multiple solutions, and each solution can produce
   multiple MIS labels since only 1 node per clause is labeled "1"
   but there can be more than 1 "true" literal per clause. HOWEVER
   any literals that are "false" for a particular CNF solution will
   always be "0" (not in the MIS) so maybe it makes sense to train
   the model to predict these.

b. The model produced multiple solutions. Maybe one or two of them
   consistently perform better than the others. I should count for
   each solution index, how often it is the "best" solution during
   training based on binary cross-entropy loss.


The same variable assignment for SAT CNF can produce multiple
labels for MIS graph, when >1 literal is true (1) per clause.
3-coloring does not have this problem.

Also 3-coloring has # nodes = # variables in CNF, whereas
MIS has a lot more nodes (# clauses * # literals per clause).